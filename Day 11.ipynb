{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "73cd69ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentences:\n",
      "['\\nNatural Language Processing (NLP) is a fascinating field of artificial intelligence. \\n', 'It focuses on the interaction between computers and humans through natural language. \\n', 'Tokenization is one of the first steps in NLP preprocessing.\\n']\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "# Load spaCy's English model\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# Sample paragraph\n",
    "paragraph = \"\"\"\n",
    "Natural Language Processing (NLP) is a fascinating field of artificial intelligence. \n",
    "It focuses on the interaction between computers and humans through natural language. \n",
    "Tokenization is one of the first steps in NLP preprocessing.\n",
    "\"\"\"\n",
    "\n",
    "# Tokenize into sentences\n",
    "doc = nlp(paragraph)\n",
    "sentences = [sent.text for sent in doc.sents]\n",
    "print(\"Tokenized Sentences:\")\n",
    "print(sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "626ba4c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
